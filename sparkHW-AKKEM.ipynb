{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fawn', ['poems', 'comedies', 'tragedies', 'histories']),\n",
       " ('heartpoor', ['poems']),\n",
       " ('nunnery', ['comedies', 'tragedies']),\n",
       " ('redeemst', ['tragedies']),\n",
       " ('woods', ['histories', 'poems', 'comedies', 'tragedies']),\n",
       " ('spiders', ['tragedies', 'comedies', 'histories']),\n",
       " ('hanging', ['poems', 'glossary', 'tragedies', 'comedies', 'histories']),\n",
       " ('offendeth', ['tragedies']),\n",
       " ('beadsmen', ['histories']),\n",
       " ('scold', ['comedies', 'histories', 'glossary', 'tragedies']),\n",
       " ('mustachio', ['histories', 'comedies']),\n",
       " ('swoopstake', ['tragedies']),\n",
       " ('godsthis', ['tragedies']),\n",
       " ('benvolio', ['tragedies']),\n",
       " ('slothful', ['histories']),\n",
       " ('pages', ['comedies', 'poems', 'histories', 'tragedies']),\n",
       " ('fullgorged', ['comedies']),\n",
       " ('appropriation', ['comedies']),\n",
       " ('holyrood', ['histories']),\n",
       " ('bringing', ['histories', 'tragedies', 'comedies']),\n",
       " ('chamberdoors', ['histories']),\n",
       " ('wooden', ['glossary', 'histories', 'comedies', 'tragedies']),\n",
       " ('magnifiest', ['histories']),\n",
       " ('broiled', ['tragedies']),\n",
       " ('chameleons', ['tragedies']),\n",
       " ('selfreproving', ['tragedies']),\n",
       " ('sooty', ['tragedies']),\n",
       " ('pizzle', ['histories']),\n",
       " ('sooth', ['glossary', 'tragedies', 'histories', 'comedies']),\n",
       " ('sustaining', ['comedies', 'poems', 'tragedies']),\n",
       " ('consenting', ['comedies']),\n",
       " ('scraped', ['histories', 'comedies']),\n",
       " ('maythat', ['histories']),\n",
       " ('backthats', ['tragedies']),\n",
       " ('errors', ['poems', 'tragedies', 'comedies']),\n",
       " ('paphos', ['poems', 'comedies']),\n",
       " ('puppetshow', ['glossary']),\n",
       " ('razeth', ['histories']),\n",
       " ('succumb', ['glossary']),\n",
       " ('shocks', ['tragedies', 'poems', 'comedies']),\n",
       " ('crouch', ['histories', 'tragedies']),\n",
       " ('committst', ['comedies']),\n",
       " ('chins', ['comedies']),\n",
       " ('siward', ['tragedies']),\n",
       " ('sunbeams', ['tragedies']),\n",
       " ('chine', ['histories', 'comedies']),\n",
       " ('china', ['comedies']),\n",
       " ('properest', ['comedies']),\n",
       " ('confronts', ['histories']),\n",
       " ('boblibindo', ['comedies'])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " import string\n",
    "allStopWords={'about':1, 'above':1, 'after':1, 'again':1, 'against':1, 'all':1, 'am':1, 'an':1, 'and':1, 'any':1, 'are':1, 'arent':1, 'as':1, 'at':1, 'be':1, 'because':1, 'been':1, 'before':1, 'being':1, 'below':1, 'between':1, 'both':1, 'but':1, 'by':1, 'cant':1, 'cannot':1, 'could':1, 'couldnt':1, 'did':1, 'didnt':1, 'do':1, 'does':1, 'doesnt':1, 'doing':1, 'dont':1, 'down':1, 'during':1, 'each':1, 'few':1, 'for':1, 'from':1, 'further':1, 'had':1, 'hadnt':1, 'has':1, 'hasnt':1, 'have':1, 'havent':1, 'having':1, 'he':1, 'hed':1, 'hell':1, 'hes':1, 'her':1, 'here':1, 'heres':1, 'hers':1, 'herself':1, 'him':1, 'himself':1, 'his':1, 'how':1, 'hows':1, 'i':1, 'id':1, 'ill':1, 'im':1, 'ive':1, 'if':1, 'in':1, 'into':1, 'is':1, 'isnt':1, 'it':1, 'its':1, 'its':1, 'itself':1, 'lets':1, 'me':1, 'more':1, 'most':1, 'mustnt':1, 'my':1, 'myself':1, 'no':1, 'nor':1, 'not':1, 'of':1, 'off':1, 'on':1, 'once':1, 'only':1, 'or':1, 'other':1, 'ought':1, 'our':1, 'ours ':1, 'ourselves':1, 'out':1, 'over':1, 'own':1, 'same':1, 'shant':1, 'she':1, 'shed':1, 'shell':1, 'shes':1, 'should':1, 'shouldnt':1, 'so':1, 'some':1, 'such':1, 'than':1, 'that':1, 'thats':1, 'the':1, 'their':1, 'theirs':1, 'them':1, 'themselves':1, 'then':1, 'there':1, 'theres':1, 'these':1, 'they':1, 'theyd':1, 'theyll':1, 'theyre':1, 'theyve':1, 'this':1, 'those':1, 'through':1, 'to':1, 'too':1, 'under':1, 'until':1, 'up':1, 'very':1, 'was':1, 'wasnt':1, 'we':1, 'wed':1, 'well':1, 'were':1, 'weve':1, 'were':1, 'werent':1, 'what':1, 'whats':1, 'when':1, 'whens':1, 'where':1, 'wheres':1, 'which':1, 'while':1, 'who':1, 'whos':1, 'whom':1, 'why':1, 'whys':1, 'with':1, 'wont':1, 'would':1, 'wouldnt':1, 'you':1, 'youd':1, 'youll':1, 'youre':1, 'youve':1, 'your':1, 'yours':1, 'yourself':1, 'yourselves':1}\n",
    "\n",
    "filename = sc.wholeTextFiles(\"shakespeare/shakespeare1\")\n",
    "filename1 = filename.map(lambda x: (x[0].encode('utf-8').split('/')[-1],x[1].encode('utf-8').translate(None,string.punctuation).lower().split()))\n",
    "def removeallstopwords(lst):\n",
    "    list1=[]\n",
    "    for res in lst:\n",
    "        if res not in allStopWords and len(res)>1:\n",
    "            list1.append(res)\n",
    "    return list1\n",
    "nostopwords = filename1.map(lambda x: (x[0],removeallstopwords(x[1])))\n",
    "values = nostopwords.flatMapValues(lambda x: x).map(lambda x: (x[1],x[0])).distinct().groupByKey()\n",
    "result  = values.map(lambda x: (x[0],list(x[1])))\n",
    "result.take(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fawn', ['comedies:3', 'histories:5', 'tragedies:4', 'poems:2']),\n",
       " ('heartpoor', ['poems:1']),\n",
       " ('nunnery', ['comedies:1', 'tragedies:5']),\n",
       " ('redeemst', ['tragedies:1']),\n",
       " ('woods', ['comedies:2', 'histories:2', 'poems:1', 'tragedies:10']),\n",
       " ('spiders', ['tragedies:2', 'comedies:2', 'histories:2']),\n",
       " ('hanging',\n",
       "  ['comedies:18', 'histories:7', 'tragedies:9', 'poems:4', 'glossary:4']),\n",
       " ('offendeth', ['tragedies:1']),\n",
       " ('beadsmen', ['histories:1']),\n",
       " ('scold', ['glossary:1', 'comedies:4', 'tragedies:1', 'histories:3']),\n",
       " ('mustachio', ['comedies:1', 'histories:1']),\n",
       " ('swoopstake', ['tragedies:1']),\n",
       " ('godsthis', ['tragedies:1']),\n",
       " ('benvolio', ['tragedies:81']),\n",
       " ('slothful', ['histories:1']),\n",
       " ('fullgorged', ['comedies:1']),\n",
       " ('appropriation', ['comedies:1']),\n",
       " ('foul', ['tragedies:72', 'histories:72', 'comedies:70', 'poems:40']),\n",
       " ('bringing', ['histories:8', 'tragedies:6', 'comedies:8']),\n",
       " ('chamberdoors', ['histories:1']),\n",
       " ('wooden', ['comedies:2', 'glossary:1', 'tragedies:3', 'histories:4']),\n",
       " ('wednesday', ['histories:6', 'comedies:3', 'tragedies:5']),\n",
       " ('broiled', ['tragedies:1']),\n",
       " ('chameleons', ['tragedies:1']),\n",
       " ('selfreproving', ['tragedies:1']),\n",
       " ('sooty', ['tragedies:1']),\n",
       " ('pizzle', ['histories:1']),\n",
       " ('sooth', ['glossary:2', 'comedies:24', 'tragedies:10', 'histories:11']),\n",
       " ('sustaining', ['tragedies:1', 'poems:2', 'comedies:1']),\n",
       " ('consenting', ['comedies:4']),\n",
       " ('scraped', ['histories:1', 'comedies:2']),\n",
       " ('maythat', ['histories:1']),\n",
       " ('backthats', ['tragedies:1']),\n",
       " ('errors', ['tragedies:3', 'comedies:15', 'poems:6']),\n",
       " ('paphos', ['comedies:2', 'poems:1']),\n",
       " ('puppetshow', ['glossary:1']),\n",
       " ('razeth', ['histories:1']),\n",
       " ('succumb', ['glossary:1']),\n",
       " ('shocks', ['poems:1', 'tragedies:1', 'comedies:1']),\n",
       " ('crouch', ['tragedies:1', 'histories:2']),\n",
       " ('committst', ['comedies:1']),\n",
       " ('chins', ['comedies:4']),\n",
       " ('siward', ['tragedies:28']),\n",
       " ('sunbeams', ['tragedies:1']),\n",
       " ('chine', ['comedies:1', 'histories:1']),\n",
       " ('china', ['comedies:1']),\n",
       " ('properest', ['comedies:1']),\n",
       " ('confronts', ['histories:1']),\n",
       " ('boblibindo', ['comedies:1']),\n",
       " ('climbed', ['histories:1'])]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "allStopWords={'about':1, 'above':1, 'after':1, 'again':1, 'against':1, 'all':1, 'am':1, 'an':1, 'and':1, 'any':1, 'are':1, 'arent':1, 'as':1, 'at':1, 'be':1, 'because':1, 'been':1, 'before':1, 'being':1, 'below':1, 'between':1, 'both':1, 'but':1, 'by':1, 'cant':1, 'cannot':1, 'could':1, 'couldnt':1, 'did':1, 'didnt':1, 'do':1, 'does':1, 'doesnt':1, 'doing':1, 'dont':1, 'down':1, 'during':1, 'each':1, 'few':1, 'for':1, 'from':1, 'further':1, 'had':1, 'hadnt':1, 'has':1, 'hasnt':1, 'have':1, 'havent':1, 'having':1, 'he':1, 'hed':1, 'hell':1, 'hes':1, 'her':1, 'here':1, 'heres':1, 'hers':1, 'herself':1, 'him':1, 'himself':1, 'his':1, 'how':1, 'hows':1, 'i':1, 'id':1, 'ill':1, 'im':1, 'ive':1, 'if':1, 'in':1, 'into':1, 'is':1, 'isnt':1, 'it':1, 'its':1, 'its':1, 'itself':1, 'lets':1, 'me':1, 'more':1, 'most':1, 'mustnt':1, 'my':1, 'myself':1, 'no':1, 'nor':1, 'not':1, 'of':1, 'off':1, 'on':1, 'once':1, 'only':1, 'or':1, 'other':1, 'ought':1, 'our':1, 'ours ':1, 'ourselves':1, 'out':1, 'over':1, 'own':1, 'same':1, 'shant':1, 'she':1, 'shed':1, 'shell':1, 'shes':1, 'should':1, 'shouldnt':1, 'so':1, 'some':1, 'such':1, 'than':1, 'that':1, 'thats':1, 'the':1, 'their':1, 'theirs':1, 'them':1, 'themselves':1, 'then':1, 'there':1, 'theres':1, 'these':1, 'they':1, 'theyd':1, 'theyll':1, 'theyre':1, 'theyve':1, 'this':1, 'those':1, 'through':1, 'to':1, 'too':1, 'under':1, 'until':1, 'up':1, 'very':1, 'was':1, 'wasnt':1, 'we':1, 'wed':1, 'well':1, 'were':1, 'weve':1, 'were':1, 'werent':1, 'what':1, 'whats':1, 'when':1, 'whens':1, 'where':1, 'wheres':1, 'which':1, 'while':1, 'who':1, 'whos':1, 'whom':1, 'why':1, 'whys':1, 'with':1, 'wont':1, 'would':1, 'wouldnt':1, 'you':1, 'youd':1, 'youll':1, 'youre':1, 'youve':1, 'your':1, 'yours':1, 'yourself':1, 'yourselves':1}\n",
    "\n",
    "filename = sc.wholeTextFiles(\"shakespeare/shakespeare1\")\n",
    "filename1 = filename.map(lambda x: (x[0].encode('utf-8').split('/')[-1],x[1].encode('utf-8').translate(None,string.punctuation).lower().split()))\n",
    "def removeallstopwords(lst):\n",
    "    list1=[]\n",
    "    for res in lst:\n",
    "        if res not in allStopWords and len(res)>1:\n",
    "            list1.append(res)\n",
    "    return list1\n",
    "nostopwords = filename1.map(lambda x: (x[0],removeallstopwords(x[1])))\n",
    "values = nostopwords.flatMapValues(lambda x: x).map(lambda x: (x[1]+ '%'+ x[0],1))#distinct().groupByKey()\n",
    "reducer = values.reduceByKey(lambda x,y : x+y)\n",
    "result  = reducer.map(lambda x: (x[0].split('%')[0],(x[0].split('%')[1]+':'+str(x[1])))).groupByKey()\n",
    "finalresult = result.map(lambda x: (x[0],list(x[1])))\n",
    "finalresult.take(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o69.saveAsTextFile.\n: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://localhost:8020/user/training/hwk3.txt already exists\n\tat org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:132)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1053)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:954)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:863)\n\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1290)\n\tat org.apache.spark.api.java.JavaRDDLike$class.saveAsTextFile(JavaRDDLike.scala:489)\n\tat org.apache.spark.api.java.JavaRDD.saveAsTextFile(JavaRDD.scala:32)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:379)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:207)\n\tat java.lang.Thread.run(Thread.java:745)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d4d1aa55e167>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mresult\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mreducer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m':'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupByKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mfinalresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mfinalresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaveAsTextFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"hwk3.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36msaveAsTextFile\u001b[1;34m(self, path, compressionCodecClass)\u001b[0m\n\u001b[0;32m   1430\u001b[0m             \u001b[0mkeyed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaveAsTextFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompressionCodec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1431\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1432\u001b[1;33m             \u001b[0mkeyed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaveAsTextFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1434\u001b[0m     \u001b[1;31m# Pair functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/spark/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    536\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m         return_value = get_return_value(answer, self.gateway_client,\n\u001b[1;32m--> 538\u001b[1;33m                 self.target_id, self.name)\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/spark/python/lib/py4j-0.8.2.1-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    298\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    299\u001b[0m                     \u001b[1;34m'An error occurred while calling {0}{1}{2}.\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m                     format(target_id, '.', name), value)\n\u001b[0m\u001b[0;32m    301\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o69.saveAsTextFile.\n: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://localhost:8020/user/training/hwk3.txt already exists\n\tat org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:132)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1053)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:954)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:863)\n\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1290)\n\tat org.apache.spark.api.java.JavaRDDLike$class.saveAsTextFile(JavaRDDLike.scala:489)\n\tat org.apache.spark.api.java.JavaRDD.saveAsTextFile(JavaRDD.scala:32)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:379)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:207)\n\tat java.lang.Thread.run(Thread.java:745)\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "\n",
    "\n",
    "allStopWords={'about':1, 'above':1, 'after':1, 'again':1, 'against':1, 'all':1, 'am':1, 'an':1, 'and':1, 'any':1, 'are':1, 'arent':1, 'as':1, 'at':1, 'be':1, 'because':1, 'been':1, 'before':1, 'being':1, 'below':1, 'between':1, 'both':1, 'but':1, 'by':1, 'cant':1, 'cannot':1, 'could':1, 'couldnt':1, 'did':1, 'didnt':1, 'do':1, 'does':1, 'doesnt':1, 'doing':1, 'dont':1, 'down':1, 'during':1, 'each':1, 'few':1, 'for':1, 'from':1, 'further':1, 'had':1, 'hadnt':1, 'has':1, 'hasnt':1, 'have':1, 'havent':1, 'having':1, 'he':1, 'hed':1, 'hell':1, 'hes':1, 'her':1, 'here':1, 'heres':1, 'hers':1, 'herself':1, 'him':1, 'himself':1, 'his':1, 'how':1, 'hows':1, 'i':1, 'id':1, 'ill':1, 'im':1, 'ive':1, 'if':1, 'in':1, 'into':1, 'is':1, 'isnt':1, 'it':1, 'its':1, 'its':1, 'itself':1, 'lets':1, 'me':1, 'more':1, 'most':1, 'mustnt':1, 'my':1, 'myself':1, 'no':1, 'nor':1, 'not':1, 'of':1, 'off':1, 'on':1, 'once':1, 'only':1, 'or':1, 'other':1, 'ought':1, 'our':1, 'ours ':1, 'ourselves':1, 'out':1, 'over':1, 'own':1, 'same':1, 'shant':1, 'she':1, 'shed':1, 'shell':1, 'shes':1, 'should':1, 'shouldnt':1, 'so':1, 'some':1, 'such':1, 'than':1, 'that':1, 'thats':1, 'the':1, 'their':1, 'theirs':1, 'them':1, 'themselves':1, 'then':1, 'there':1, 'theres':1, 'these':1, 'they':1, 'theyd':1, 'theyll':1, 'theyre':1, 'theyve':1, 'this':1, 'those':1, 'through':1, 'to':1, 'too':1, 'under':1, 'until':1, 'up':1, 'very':1, 'was':1, 'wasnt':1, 'we':1, 'wed':1, 'well':1, 'were':1, 'weve':1, 'were':1, 'werent':1, 'what':1, 'whats':1, 'when':1, 'whens':1, 'where':1, 'wheres':1, 'which':1, 'while':1, 'who':1, 'whos':1, 'whom':1, 'why':1, 'whys':1, 'with':1, 'wont':1, 'would':1, 'wouldnt':1, 'you':1, 'youd':1, 'youll':1, 'youre':1, 'youve':1, 'your':1, 'yours':1, 'yourself':1, 'yourselves':1}\n",
    "def removeallstopwords(lst):\n",
    "    list1=[]\n",
    "    for res in lst:\n",
    "        if res not in allStopWords and len(res)>1:\n",
    "            list1.append(res)\n",
    "    return list1\n",
    "filename = sc.wholeTextFiles(\"MapReduceData1/MapReduceData/hw3data\")\n",
    "filename1 = filename.flatMap(lambda x: (x[1].strip().split('\\n'))).map(lambda x: x.encode('ascii','ignore').split(':::')).map(lambda x: (x[1],x[2].lower().split()))\n",
    "nostopwords = filename1.map(lambda x: (x[0],removeallstopwords(x[1]))).flatMapValues(lambda x : x).map(lambda x: (x[1],x[0].split(\"::\")))\n",
    "values = nostopwords.flatMapValues(lambda x: x).map(lambda x: (x[1]+ '%'+ x[0],1))\n",
    "reducer = values.reduceByKey(lambda x,y : x+y)\n",
    "result  = reducer.map(lambda x: (x[0].split('%')[0],(x[0].split('%')[1]+':'+str(x[1])))).groupByKey()\n",
    "finalresult = result.map(lambda x: (x[0],list(x[1])))\n",
    "finalresult.saveAsTextFile(\"hwk3.txt\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
